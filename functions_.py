# -*- coding: utf-8 -*-
"""Functions_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hnydNPZHipPutJKiZkxEYBPJ3oBl71oH
"""



"""## Imports"""

import io
import os
import gzip
import json
import scipy
import random
import warnings
import numpy as np
import numba as nb
import pandas as pd
import datetime as dt
import seaborn as sns
from tqdm import tqdm
import itertools
import scipy.stats as st
import scipy.sparse as sparse
from scipy.linalg import orth
import matplotlib.pyplot as plt
from numpy import linalg as lin
warnings.filterwarnings('ignore')
from scipy.sparse import coo_matrix
from scipy.sparse.linalg import svds
from datetime import datetime as dt_dt
from scipy.sparse.linalg import spsolve
from numpy.linalg import qr as QR_decomp
from collections import OrderedDict
from scipy.sparse import csr_matrix, find
from pandas.api.types import CategoricalDtype



"""## Imports"""

import io
import os
import gzip
import json
import scipy
import random
import warnings
import numpy as np
import numba as nb
import pandas as pd
import datetime as dt
import seaborn as sns
from tqdm import tqdm
import itertools
import scipy.stats as st
import scipy.sparse as sparse
from scipy.linalg import orth
import matplotlib.pyplot as plt
from numpy import linalg as lin
warnings.filterwarnings('ignore')
from scipy.sparse import coo_matrix
from scipy.sparse.linalg import svds
from datetime import datetime as dt_dt
from scipy.sparse.linalg import spsolve
from numpy.linalg import qr as QR_decomp
from collections import OrderedDict
from scipy.sparse import csr_matrix, find
from pandas.api.types import CategoricalDtype

"""## Functions

### 1.Data Split
"""

def getPivotMonths(DF,time_column,N_TMonths):
    pivotMonths_list = []
    ts = DF[time_column]
    for n in range(1,N_TMonths+1):
        pivotMonth = ts.max() - pd.DateOffset(months=n)
        pivotMonths_list.append(pivotMonth)
    return pivotMonths_list

def Time_DataSplit(DF,time_column,pivotMonths_list,N_TMonths,n_train): 
    ΔA_list = []
    ts = DF[time_column]
    A0_df = DF.loc[ts < pivotMonths_list[-1]] 
    ΔA1 = DF.loc[ts >= pivotMonths_list[0]]    #last time step..
    ΔA_list.append(ΔA1)  
    for i in range(N_TMonths-1):
        ΔA = DF.loc[(ts >= pivotMonths_list[i+1]) & (ts < pivotMonths_list[i])]
        ΔA_list.append(ΔA)
    ΔA_list =  ΔA_list[::-1]          #reverse order..
    ΔA_train = ΔA_list[:n_train]  
    ΔA_test = ΔA_list[n_train:]   
    return A0_df,ΔA_train,ΔA_test

def TestTrain_DataSplit(DF,user_column,time_column,pivotMonths_list,ΔA_test):
    AllDF_list  = []
    PSITest_list   = []
    HOLDOUT_list   = []
    ts = DF[time_column]
    for test_ in ΔA_test:
        test_sorted = test_.sort_values(time_column)
        test_idx = [x[-1] for x in test_sorted.index.groupby(test_sorted[user_column]).values()]
    
        holdout = test_.loc[test_idx]
        psi_test = test_.drop(test_idx)
        all_df_ = DF.loc[ts <= test_[time_column].max()]           
        
        PSITest_list.append(psi_test)
        HOLDOUT_list.append(holdout)
        AllDF_list.append(all_df_)
    return AllDF_list, PSITest_list, HOLDOUT_list

"""### 2.Rating Matrices"""

def SingleRatingMatrix(DF,user_column,product_column,rows_,cols_):  ##rows_ = n_users,cols_ = n_items
    rows0 = DF[user_column].values
    cols0 = DF[product_column].values
    data  = np.broadcast_to(1., DF.shape[0]) # ignore ratings

    A0_Rating_matrix = coo_matrix((data, (rows0, cols0)), shape=(rows_, cols_)).tocsr()
    if A0_Rating_matrix.nnz < len(data):
        # there were duplicates accumulated by .tocsr() -> need to make it implicit
        A0_Rating_matrix = A0_Rating_matrix._with_data(np.broadcast_to(1., A0_Rating_matrix.nnz), copy=False)

    return A0_Rating_matrix


def AllRatingMatrices(DFList,user_column,product_column,rows_ ,cols_):
    Rating_matrix_list = []
    for df in DFList:
        df_Mat = SingleRatingMatrix(df,user_column,product_column,rows_, cols_)
        Rating_matrix_list.append(df_Mat)
    return Rating_matrix_list               #return the list of Rating matrices


#######################################################################
      ##get Rating Matrices based on single step interaction only 
def SingleStep_RatMat(DF,user_column,item_column):  ##rows_ = n_users,cols_ = n_items
    rows_ = DF[user_column].nunique() 
    cols_ = DF[item_column].nunique() 
    
    rows0 = DF[user_column].values
    cols0 = DF[item_column].values
    data  = np.broadcast_to(1., DF.shape[0]) # ignore ratings

    A0_Rating_matrix = coo_matrix((data, (rows0, cols0)), shape=(rows_, cols_)).tocsr()
    if A0_Rating_matrix.nnz < len(data):
        # there were duplicates accumulated by .tocsr() -> need to make it implicit
        A0_Rating_matrix = A0_Rating_matrix._with_data(np.broadcast_to(1., A0_Rating_matrix.nnz), copy=False)

    return A0_Rating_matrix

def All_SingleStepRatMat(DFList,user_column,item_column):
    Rating_matrix_list = []
    for df in DFList:
        df_Mat = SingleStep_RatMat(df,user_column,item_column)
        Rating_matrix_list.append(df_Mat)
    return Rating_matrix_list               #return the list of Rating matrices

#################################################################################

def psiStep_RatMat(DF,All_DF,user_column,item_column):  ##rows_ = n_users,cols_ = n_items
    rows_ = All_DF[user_column].nunique() 
    cols_ = All_DF[item_column].nunique() 
    
    rows0 = DF[user_column].values
    cols0 = DF[item_column].values
    data  = np.broadcast_to(1., DF.shape[0]) # ignore ratings

    A0_Rating_matrix = coo_matrix((data, (rows0, cols0)), shape=(rows_, cols_)).tocsr()
    if A0_Rating_matrix.nnz < len(data):
        # there were duplicates accumulated by .tocsr() -> need to make it implicit
        A0_Rating_matrix = A0_Rating_matrix._with_data(np.broadcast_to(1., A0_Rating_matrix.nnz), copy=False)

    return A0_Rating_matrix

def psiAllStep_RatMat(DFList,All_DF_list,user_column,product_column):
    Rating_matrix_list = []
    for df,all_df in zip(DFList,All_DF_list):
        df_Mat = psiStep_RatMat(df,all_df,user_column,product_column)
        Rating_matrix_list.append(df_Mat)
    return Rating_matrix_list               #return the list of Rating matrices

"""### 3.Find new users and items"""

def Find_NewUsersItems(AllDF_start,AllDF_list,user_column,item_column,N_steps=8):
    New_usersList = []
    prev_users_1 =  AllDF_start[user_column].unique()       #
    new_step_users_1 = AllDF_list[0][user_column].unique()
    new_users_1 = np.setdiff1d(new_step_users_1,prev_users_1)  #elements in 'new_step_users' not in 'all_prev_users' == new_users
    New_usersList.append(new_users_1)

    New_itemsList = []
    prev_items_1 =     AllDF_start[item_column].unique()            #
    new_step_items_1 = AllDF_list[0][item_column].unique()
    new_items_1 = np.setdiff1d(new_step_items_1,prev_items_1)  #elements in 'new_step_items' not in 'all_prev_items' == new_items
    New_itemsList.append(new_items_1)

    for i in range(N_steps-1):
        prev_users = AllDF_list[i][user_column].unique()    ## i == for SVD
        step_users=  AllDF_list[i+1][user_column].unique()    ##(i+1) == for incremental 
        new_users = np.setdiff1d(step_users,prev_users)  ##elements in 'new_step_users' not in 'all_prev_users' == new_users
        New_usersList.append(new_users)

        prev_items = AllDF_list[i][item_column].unique()    ## i == for SVD
        step_items=  AllDF_list[i+1][item_column].unique()    ##(i+1) == for incremental 
        new_items = np.setdiff1d(step_items,prev_items)  ##elements in 'new_step_users' not in 'all_prev_users' == new_users
        New_itemsList.append(new_items)
    return New_usersList,New_itemsList

"""### 3.P.S.I on Rating Matrices"""

##INPUTS: factorization of the rank-r matrix Y(0) = USV and the increment ΔA 
def integrator(U0,S0,V0,ΔA):
  K1 = U0 @ S0 + ΔA @ V0                #1st step is to find K1 from inital inputs...
  U1,S1_cap =  QR_decomp(K1)            #compute the QR_decomposition of K1 
  S0_tilde = S1_cap - U1.T @ ΔA @ V0
  L1 = V0 @ S0_tilde.T + ΔA.T @ U1
  V1,S1_T =  QR_decomp(L1)                  #compute the QR_decomposition of L1
  S1 = S1_T.T
  return U1,S1,V1


def getStartingValues(A0,k):
  U, S, VT = svds(A0,k=k)
  V = VT.T
  S = np.diag(S)
  return U,S,V


def integratorOnMat(A0,ΔA_train_matrix,ΔA_test_matrix,k):
  U,S,V = getStartingValues(A0,k)          ##technically the starting point U, S, V here are U0, S0, V0T
  for ΔA in ΔA_train_matrix:
    U,S,V = integrator(U,S,V,ΔA)            ##the last U,S,V from this ΔA_train are the starting elements for the ΔA_test  
    
  V_list = []  
  for ΔA in ΔA_test_matrix:
    U,S,V = integrator(U,S,V,ΔA)
    V_list.append(V)
  return V_list


def last_psiTrainMat(A0,ΔA_train_matrix,k):
  U,S,V = getStartingValues(A0,k)          ##technically the starting point U, S, V here are U0, S0, V0T
  for ΔA in tqdm(ΔA_train_matrix):
    U,S,V = integrator(U,S,V,ΔA)            ##the last U,S,V from this ΔA_train are the starting elements for the ΔA_test      
  return U,S,V

"""### 5.Row Update:"""

def Updt_RowMatrix(DF,user_column,item_column,itemID_dict,rows_,cols_):  ##rows_ = n_users,cols_ = n_items
    rows0 = DF[user_column].values                       

    Original_itemID = DF[item_column].values                   ##== dict_key..
    cols0 = [itemID_dict.get(item) for item in Original_itemID]   ##== dict_values || get the updated_ids ...          
    data  = np.broadcast_to(1., DF.shape[0]) # ignore rating
    A0_Rating_matrix = coo_matrix((data, (rows0, cols0)), shape=(rows_, cols_)).tocsr()
    if A0_Rating_matrix.nnz < len(data):
        A0_Rating_matrix = A0_Rating_matrix._with_data(np.broadcast_to(1., A0_Rating_matrix.nnz), copy=False)

    return A0_Rating_matrix    

def getRow_Mat(DF_curr,newUSER_id,In_DomainListITEMS,Vi,itemID_dict,user_column,item_column):  #Same num items: as prev step      
    n_cols = Vi.shape[0]                                                   
    new_Userrow = DF_curr[DF_curr[user_column]==newUSER_id] #get  all items bought by the newUser so far 
    itemsbought = new_Userrow[item_column].unique().tolist()         #get all items the newuser has bought
    Out_DomainItem_ = np.setdiff1d(itemsbought,In_DomainListITEMS)   #get newItems the newUsers interacted with

    if len(Out_DomainItem_)== 0:          #if there is no NewItems in NewUser interaction: then update user
       new_Userrow['new_userId'] = 0
       newUser_mat = Updt_RowMatrix(new_Userrow,'new_userId',item_column,itemID_dict,1,n_cols)
       A_row = newUser_mat.todense()        

    else:    #if there is(are) NewItem(s) in the items NewUser has interacted with: update users with only the old items
       In_DomainItem_ = np.intersect1d(itemsbought, In_DomainListITEMS)   #get old items users interacted with only
       newUser_oldItems  = new_Userrow.loc[new_Userrow[item_column].isin(In_DomainItem_) ]  #incase its more than 1 item
       newUser_oldItems['new_userId'] = 0
       newUser_mat = Updt_RowMatrix(newUser_oldItems,'new_userId',item_column,itemID_dict,1,n_cols)
       A_row = newUser_mat.todense()                 #row_matrix of new_user

    return A_row 

def row_update(U0,S0,V0,A_row,k,Forced_Orth=False):
    Sn = len(S0)
    Sdiag = np.eye(Sn)*S0    #diag matrix  (r X r)
    V = U0
    U = V0
    S = Sdiag
    A = A_row.T
    rank = U.shape[1]
    m = np.dot(U.T,A)         #m = UTA || A : Matrix of additional data
    p = A - np.dot(U,m)       #p = (A - UUTA) || [1-UUT]A 
    P = orth(p)               #Orthogonal basis of p  
    Ra = np.dot(P.T,p)

    z = np.zeros(m.shape)

    upper_ = np.hstack((Sdiag,m)) 
    lower_ = np.hstack((z.T,Ra))    
    K = np.vstack((upper_,lower_))  #Eqn-9 || K = [(S m);(0, Ra)]
    U1,S1,V1 = lin.svd(K)           ##Full k_decomposition  
    Uupdt = U1[:,:rank]             ##clip K decomposition to rank
    Supdt = np.diag(S1[:rank])
    Vupdt = V1[:,:rank]
                                             ##get update
    U_updt = np.dot(np.hstack((U,P)),Uupdt)  ##[U P]U`
    n = Vupdt.shape[0] 
    Vp_    = np.dot(V,Vupdt[:rank,:])
    V_updt = np.vstack((Vp_, Vupdt[rank:n, :]))

    if Forced_Orth:
       Uq, Ur = lin.qr(U_updt) 
       Vq, Vr = lin.qr(V_updt)
       Ur_S = np.dot(Ur,Supdt)
       K_orth = np.dot(Ur_S,Vr.T)
       U2,S2,V2 = lin.svd(K_orth)

       Supdt = np.diag(S2)
       U_updt = np.dot(Uq,U2)
       V_updt = np.dot(Vq,V2)
    
    U_updated = np.array(V_updt)
    S_updated = Supdt
    V_updated = np.array(U_updt)
    return U_updated,S_updated,V_updated

"""### 5.Column Update:"""

def Updt_ColMatrix(DF,user_column,item_column,userID_dict,rows_,cols_):  ##rows_ = n_users,cols_ = n_items
    cols0 = DF[item_column].values

    Original_UserID = DF[user_column].values                        ##== dict_key..
    rows0 = [userID_dict.get(item) for item in Original_UserID]     ##== dict_values || get the updated_ids ...  
    data  = np.broadcast_to(1., DF.shape[0]) # ignore ratings

    A0_Rating_matrix = coo_matrix((data, (rows0, cols0)), shape=(rows_, cols_)).tocsr()
    if A0_Rating_matrix.nnz < len(data):
        A0_Rating_matrix = A0_Rating_matrix._with_data(np.broadcast_to(1., A0_Rating_matrix.nnz), copy=False)

    return A0_Rating_matrix


def getCol_Mat(DF_curr,newITEM_id,In_DomainListUSERS,Ui,userID_dict,user_column,item_column):  #Same num users: as the previous step     
    n_rows = Ui.shape[0]    
    new_Itemcol = DF_curr[DF_curr[item_column]==newITEM_id]   #get all item_df                                                   
    users_whobought = new_Itemcol[user_column].unique().tolist()         #get all users that bought the newitem 
    Out_DomainUser_ = np.setdiff1d(users_whobought,In_DomainListUSERS)   #get newUsers that bought the new item 

    if len(Out_DomainUser_)== 0:   ##if No new user bought the new item: update item with the indomain users
       new_Itemcol['new_itemId'] = 0
       newItem_mat = Updt_ColMatrix(new_Itemcol,user_column,'new_itemId',userID_dict,n_rows,1)
       A_col = newItem_mat.todense()                
 
    else:                   #if there is(are) NewUser(s) that bought the newItems: update items with only the old users
       In_DomainUser_ = np.intersect1d(users_whobought,In_DomainListUSERS) 
       newItem_oldUser  = new_Itemcol.loc[new_Itemcol[user_column].isin(In_DomainUser_)] #get the old  users that bought the item with only
       newItem_oldUser['new_itemId'] = 0
       newItem_mat = Updt_ColMatrix(newItem_oldUser,user_column,'new_itemId',userID_dict,n_rows,1)
       A_col = newItem_mat.todense()              
       
    return A_col

def colunm_update(U0,S0,V0,A_column,k,Forced_Orth=False):
    Sn = len(S0)
    Sdiag = np.eye(Sn)*S0    #diag matrix  (r X r)
    V = V0
    U = U0
    S = Sdiag
    A = A_column
    rank = U.shape[1]
    m = np.dot(U.T,A)         #m = UTA || A : Matrix of additional data
    p = A - np.dot(U,m)       #p = (A - UUTA) || [1-UUT]A 
    P = orth(p)               #Orthogonal basis of p  
    Ra = np.dot(P.T,p)
    z = np.zeros(m.shape)

    upper_ = np.hstack((Sdiag,m)) 
    lower_ = np.hstack((z.T,Ra))    
    K = np.vstack((upper_,lower_))  #Eqn-9 || K = [(S m);(0, Ra)]
    U1,S1,V1 = lin.svd(K)           ##Full k_decomposition  
    Uupdt = U1[:,:rank]             ##clip K decomposition to rank
    Supdt = np.diag(S1[:rank])
    Vupdt = V1[:,:rank]
                                             ##get update
    U_updt = np.dot(np.hstack((U,P)),Uupdt)  ##[U P]U`
    n = Vupdt.shape[0] 
    Vp_    = np.dot(V,Vupdt[:rank,:])
    V_updt = np.vstack((Vp_, Vupdt[rank:n, :]))

    if Forced_Orth:
       Uq, Ur = lin.qr(U_updt) 
       Vq, Vr = lin.qr(V_updt)
       Ur_S = np.dot(Ur,Supdt)
       K_orth = np.dot(Ur_S,Vr.T)
       U2,S2,V2 = lin.svd(K_orth)

       Supdt = np.diag(S2)
       U_updt = np.dot(Uq,U2)
       V_updt = np.dot(Vq,V2)
    
    U_updated = np.array(U_updt)
    S_updated = Supdt
    V_updated = np.array(V_updt)
    return U_updated,S_updated,V_updated

"""### RowCol Update"""

def UsersItems_RatPair(DF_curr,newUSER_id,newITEM_id,In_DomainListUSERS,In_DomainListITEMS,userID_dict,itemID_dict,Ui,Vi,user_column,item_column):    
    new_Userrow = DF_curr[DF_curr[user_column]==newUSER_id] #get  all items bought by the newUser so far 
    n_cols = Vi.shape[0]                           #n_cols = newITEM_id : num_cols in prev update == PREV['productId'].nunique() == newItem_Id
    itemsbought = new_Userrow[item_column].unique().tolist()         #get all items the newuser has bought
    Out_DomainItem_ = np.setdiff1d(itemsbought,In_DomainListITEMS)   #get newItems the newUsers interacted with

    if len(Out_DomainItem_)== 0:          #if there is no NewItems in NewUser interaction: then update user
       new_Userrow['new_userId'] = 0
       newUser_mat = Updt_RowMatrix(new_Userrow,'new_userId',item_column,itemID_dict,1,n_cols)
       A_row = newUser_mat.todense()        #row_matrix of new_user
 
    else:    #if len(Out_DomainItem_) != 0: #if there is(are) NewItem(s) in the items NewUser has interacted with: update users with only the old items
       In_DomainItem_ = np.intersect1d(itemsbought, In_DomainListITEMS)   #get old items users interacted with only
       newUser_oldItems  = new_Userrow.loc[new_Userrow[item_column].isin(In_DomainItem_) ]  #incase its more than 1 item
       newUser_oldItems['new_userId'] = 0
       newUser_mat = Updt_RowMatrix(newUser_oldItems,'new_userId',item_column,itemID_dict,1,n_cols)
       A_row = newUser_mat.todense()                 #row_matrix of new_user

    new_Itemcol = DF_curr[DF_curr[item_column]==newITEM_id]   #get all users that bought the newItem so far 
    n_rows = Ui.shape[0] +1                                   #Now num of user has increased by 1 ||n_rows: Numof users in last update
    users_whobought = new_Itemcol[user_column].unique().tolist()         #get all users that bought the newitem 
    Out_DomainUser_ = np.setdiff1d(users_whobought,In_DomainListUSERS)   #get newUsers that bought the new item 

    if len(Out_DomainUser_)== 0:   ##if No new user bought the new item: update item with the indomain users
       new_Itemcol['new_itemId'] = 0
       newItem_mat = Updt_ColMatrix(new_Itemcol,user_column,'new_itemId',userID_dict,n_rows,1)
       A_col = newItem_mat.todense()                
 
    else:       #if there is(are) NewUser(s) that bought the newItems: update items with only the old users
       In_DomainUser_ = np.intersect1d(users_whobought,In_DomainListUSERS) 
       newItem_oldUser  = new_Itemcol.loc[new_Itemcol[user_column].isin(In_DomainUser_)] #get the old  users that bought the item with only
       newItem_oldUser['new_itemId'] = 0
       newItem_mat = Updt_ColMatrix(newItem_oldUser,user_column,'new_itemId',userID_dict,n_rows,1)
       A_col = newItem_mat.todense()              
    return A_row, A_col

def getRowCol_psiupdt(U_prev,S_prev,V_prev, A_row,A_col,k=50,Forced_Orth=False):  #Alternating ... 
    U_Row,S_Row,V_Row = row_update(U_prev,S_prev,V_prev,A_row,k,Forced_Orth)    ##user_updt b4 item_updt
    U_ColRow,S_ColRow,V_ColRow = colunm_update(U_Row,S_Row,V_Row,A_col,k,Forced_Orth)  

    return  U_ColRow,S_ColRow,V_ColRow

"""### Check Deffred Status"""

def ITEMS_defferredStatus(DF_curr,ITEMS_list,defferredItem_list,In_DomainListUSERS,user_column,item_column): #check if item only have new (out-domain) users
    newITEM_id = ITEMS_list[0]
    new_Itemcol = DF_curr[DF_curr[item_column]==newITEM_id]             #get newitem_df 
    users_whobought = new_Itemcol[user_column].unique().tolist()        #get all users that bought the newitem 
    In_DomainUser_ = np.intersect1d(users_whobought,In_DomainListUSERS) #get the old  users that bought the item with only

    if len(In_DomainUser_) == 0:   #if there is(are) NO OldUser(s) that bought the newItems:
       status = True 
       defferredItem_list.append(ITEMS_list.pop(ITEMS_list.index(newITEM_id))) #remove the item from the itemlist and put into defferred list

    else:           #if there is(are)  OldUser(s) that  bought the newItems: 
       status = False  

    defferredItem_LIST = defferredItem_list
    return status, ITEMS_list,defferredItem_LIST 


def USERS_defferredStatus(DF_curr,USERS_list,defferredUsers_list,In_DomainListITEMS,user_column,item_column): #check if item only have new (out-domain) users
    newUSER_id = USERS_list[0]
    new_Userrow = DF_curr[DF_curr[user_column]==newUSER_id]        #get  newUser_df items bought by the newUser so far  
    itemsbought = new_Userrow[item_column].unique().tolist()       #get all items the newuser has bought
    In_DomainItem_ = np.intersect1d(itemsbought, In_DomainListITEMS)  #get old items users interacted with only

    if len(In_DomainItem_) == 0:   #if there is(are) NO OldItem(s) that the user bought:
       status = True 
       defferredUsers_list.append(USERS_list.pop(USERS_list.index(newUSER_id))) #remove the item from the itemlist and put into defferred list
      
    else:          #if there is(are)  OldUser(s) that  bought the newItems: 
       status = False  
      
    defferredUsers_LIST = defferredUsers_list
    return status, USERS_list,defferredUsers_LIST



"""### Get All V_list"""

def V_listUpdate(DF_curr,Defferred_Items,Defferred_Users,ITEMS_list,USERS_list,In_DomainListUSERS,In_DomainListITEMS,
                 userID_dict,itemID_dict,Ui,Si,Vi):

    item_len = len(ITEMS_list)
    user_len = len(USERS_list)
    print()
    for i in tqdm(range(max(item_len,user_len))):
        Item_isCold = True   
        User_isCold = True 
        while (User_isCold) & (len(USERS_list) !=  0) :                #check if untill status==0
              User_isCold, USERS_list, Defferred_Users = USERS_defferredStatus(DF_curr,USERS_list,Defferred_Users,
                                                                         In_DomainListITEMS,'userId','productId')          
              print("Is_UserCold? :",User_isCold)


        while (Item_isCold) & (len(ITEMS_list) !=  0) :           #check if untill status==0
              Item_isCold, ITEMS_list, Defferred_Items = ITEMS_defferredStatus(DF_curr,ITEMS_list,Defferred_Items,
                                                                         In_DomainListUSERS,'userId','productId')          
              print("Is_ItemCold? :",Item_isCold)

        if (len(ITEMS_list) !=  0) &  (len(USERS_list) !=  0):      #if items & users are still available in  after the checks..:
           newITEM_id = ITEMS_list[0]                               #do row:col update   
           newUSER_id = USERS_list[0]
           print(newUSER_id,newITEM_id)
           userID_dict[newUSER_id] = list(userID_dict.values())[-1]+1   #updated the userId
           itemID_dict[newITEM_id] = list(itemID_dict.values())[-1]+1   #updated the itemId
           A_row,A_col = UsersItems_RatPair(DF_curr,newUSER_id,newITEM_id,In_DomainListUSERS,In_DomainListITEMS,userID_dict,
                                            itemID_dict,Ui,Vi,'userId','productId')

           Ui,Si,Vi = getRowCol_psiupdt(Ui,Si,Vi, A_row,A_col,k=50,Forced_Orth=False)  
           In_DomainListUSERS.append(newUSER_id)        #LstUpdted_User = newUSER_id
           In_DomainListITEMS.append(newITEM_id)  

           ITEMS_list.pop(ITEMS_list.index(newITEM_id))  #remove the updated item from the list   
           USERS_list.pop(USERS_list.index(newUSER_id))  #remove the updated user from the list     
       
           item_len = len(ITEMS_list)
           user_len = len(USERS_list)
           print()                                                               
                                                                
        if (len(USERS_list) !=  0) & (len(ITEMS_list) ==  0) :    #if item cataloge is empty and users are still available                                                         
           newUSER_id = USERS_list[0]                             #switch to row update  after exhausting available items
           userID_dict[newUSER_id] = list(userID_dict.values())[-1]+1   #updated the userId

           A_row = getRow_Mat(DF_curr,newUSER_id,In_DomainListITEMS,Vi,itemID_dict,'userId','productId')    #update rest of available users         
           Ui,Si,Vi = row_update(Ui,Si,Vi,A_row,k=50,Forced_Orth=False)

           In_DomainListUSERS.append(newUSER_id)  
           USERS_list.pop(USERS_list.index(newUSER_id))  #remove the updated user from the list
           user_len = len(USERS_list)
           print()

        if (len(ITEMS_list) !=  0) & (len(USERS_list) ==  0) : #if user cataloge is empty and items are still available   
           newITEM_id = ITEMS_list[0]                          #switch to col update  after exhausting available users 
           itemID_dict[newITEM_id] = list(itemID_dict.values())[-1]+1   #updated the itemId                                       
           A_col = getCol_Mat(DF_curr,newITEM_id,In_DomainListUSERS,Ui,userID_dict,'userId','productId')    #update rest of available items         
           Ui,Si,Vi = colunm_update(Ui,Si,Vi,A_col,k=50,Forced_Orth=False)
           #print('New nuser: New nitem:',Ui.shape[0],Vi.shape[0])  
           In_DomainListITEMS.append(newITEM_id)   
           ITEMS_list.pop(ITEMS_list.index(newITEM_id))  #remove the updated item from the list
           item_len = len(ITEMS_list)
           print()
    return Defferred_Items,Defferred_Users,In_DomainListUSERS,In_DomainListITEMS,userID_dict,itemID_dict,Ui,Si,Vi



"""###All Step Update"""

def SingleStep_UPDATE(DF_curr,Defferred_Items,Defferred_Users,ITEMS_list,USERS_list,In_DomainListUSERS,In_DomainListITEMS,
                      userID_dict,itemID_dict,U_list,S_list,V_list):
    Ui,Si,Vi = U_list[-1],S_list[-1],V_list[-1]
    print("1st Updating Phase..")
    DItems_1, DUsers_1,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,U1,S1,V1 = V_listUpdate(DF_curr,Defferred_Items,Defferred_Users,
                                                 ITEMS_list,USERS_list,In_DomainListUSERS,In_DomainListITEMS,userID_dict,itemID_dict,Ui,Si,Vi)

    ITEMS_list = DItems_1  # transfer deferred into item&user lists
    USERS_list = DUsers_1
    DefferredItems_2 = []
    DefferredUsers_2 = []

    print("2nd Updating Phase..")
    DItems_2, DUsers_2,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,U2,S2,V2 = V_listUpdate(DF_curr,DefferredItems_2,DefferredUsers_2,
                                         ITEMS_list,USERS_list,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,U1,S1,V1)
    
    U_list.append(U2)
    S_list.append(S2)
    V_list.append(V2)
    UpdtUSERS_list = In_DomainUSERS.copy()
    UpdtITEMS_list = In_DomainITEMS.copy()
    return DItems_2, DUsers_2,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,UpdtUSERS_list,UpdtITEMS_list,U_list,S_list,V_list


def ALLSTEPs_update(AllDF_start,AllDF_list,New_itemsList,New_usersList,U_list,S_list,V_list,Nsteps=8):
    DF_curr = AllDF_list[0][['userId','productId']]

    Defferred_Items = []
    Defferred_Users = []
    AllUpdtUSERS_List = []
    AllUpdtITEMS_List = []

    ITEMS_list =  New_itemsList[0].tolist() ##out of domain
    USERS_list =  New_usersList[0].tolist()
    In_DomainListUSERS =  AllDF_start['userId'].unique().tolist()     
    In_DomainListITEMS =  AllDF_start['productId'].unique().tolist()
    userID_dict = {item: idx for idx, item in enumerate(In_DomainListUSERS)}
    itemID_dict = {item: idx for idx, item in enumerate(In_DomainListITEMS)}
    DItems_, DUsers_,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,UpdtUSERS_,UpdtITEMS_,U_list,S_list,V_list = SingleStep_UPDATE(DF_curr,Defferred_Items,
                                                               Defferred_Users,ITEMS_list,USERS_list,In_DomainListUSERS,In_DomainListITEMS,
                                                               userID_dict,itemID_dict,U_list,S_list,V_list)
    AllUpdtUSERS_List.append(UpdtUSERS_)
    AllUpdtITEMS_List.append(UpdtITEMS_)
    for i in tqdm(range(1,Nsteps)):
        Defferred_Items = []
        Defferred_Users = []
      
        ITEMS_list =  New_itemsList[i].tolist()+DItems_ ##append previously defferred items to newlist
        USERS_list =  New_usersList[i].tolist()+DUsers_

        DF_curr_ = AllDF_list[i][['userId','productId']]
        DItems_, DUsers_,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,UpdtUSERS_,UpdtITEMS_,U_list,S_list,V_list= SingleStep_UPDATE(DF_curr_,
                                                            Defferred_Items,Defferred_Users,ITEMS_list,USERS_list,In_DomainUSERS,
                                                            In_DomainITEMS,userID_dict,itemID_dict,U_list,S_list,V_list)
        AllUpdtUSERS_List.append(UpdtUSERS_)
        AllUpdtITEMS_List.append(UpdtITEMS_)

    return DItems_, DUsers_,In_DomainUSERS,In_DomainITEMS,userID_dict,itemID_dict,AllUpdtUSERS_List,AllUpdtITEMS_List,U_list,S_list,V_list



"""### Dataset Adjustments """

def get_NEWHoldout(HOLDOUT_list,userID_dict,itemID_dict,AllUpdtUSERS_,AllUpdtITEMS_,n):
    newHOLDOUT_LIST =  []
    for i in tqdm(range(n)):
        Updt_Items  =   AllUpdtITEMS_[i]
        Updt_Users  =   AllUpdtUSERS_[i]     
        newHOLDOUT_ =   HOLDOUT_list[i].loc[(HOLDOUT_list[i]['productId'].isin(Updt_Items)) & (HOLDOUT_list[i]['userId'].isin(Updt_Users))]#
        newHOLDOUT_ =   newHOLDOUT_[['userId','productId']]

        prevUser_ID =   newHOLDOUT_['userId'].values  ##
        prevItems_ID =  newHOLDOUT_['productId'].values   #
        Updted_UserID = [userID_dict.get(user) for user in prevUser_ID]   
        Updted_ItemID = [itemID_dict.get(item) for item in prevItems_ID]

        newHOLDOUT_['Updated_UserID'] = Updted_UserID
        newHOLDOUT_['Updated_ItemID'] = Updted_ItemID
        newHOLDOUT_LIST.append(newHOLDOUT_)
    return  newHOLDOUT_LIST

def adjustedAllDF(AllDF_list,userID_dict,itemID_dict,AllUpdtUSERS_,AllUpdtITEMS_,n):
    newAllDF_list =[]
    for i in range(n):
        AllDF_list[i] = AllDF_list[i][['userId','productId']]
        Updt_Items    = AllUpdtITEMS_[i]
        Updt_Users    = AllUpdtUSERS_[i]     
        allnew_df     = AllDF_list[i].loc[(AllDF_list[i]['productId'].isin(Updt_Items)) & (AllDF_list[i]['userId'].isin(Updt_Users))]

        prevUser_ID =   allnew_df['userId'].values  
        prevItems_ID =  allnew_df['productId'].values   
        Updted_UserID = [userID_dict.get(user) for user in prevUser_ID]   
        Updted_ItemID = [itemID_dict.get(item) for item in prevItems_ID]
        allnew_df['Updated_UserID'] = Updted_UserID
        allnew_df['Updated_ItemID'] = Updted_ItemID
        newAllDF_list.append(allnew_df)
    return newAllDF_list

def adjustedPSI_DF(PSITest_list,,userID_dict,itemID_dict,AllUpdtUSERS_,AllUpdtITEMS_,n):
    new_PSIDFlist =[]
    for i in range(n):
        PSITest_list[i] = PSITest_list[i][['userId','productId']]
        Updt_Items    = AllUpdtITEMS_[i]
        Updt_Users    = AllUpdtUSERS_[i]     
        new_PSIdf     = PSITest_list[i].loc[(PSITest_list[i]['productId'].isin(Updt_Items)) & (PSITest_list[i]['userId'].isin(Updt_Users))]

        prevUser_ID =   new_PSIdf['userId'].values  
        prevItems_ID =  new_PSIdf['productId'].values   
        Updted_UserID = [userID_dict.get(user) for user in prevUser_ID]   
        Updted_ItemID = [itemID_dict.get(item) for item in prevItems_ID]
        new_PSIdf['Updated_UserID'] = Updted_UserID
        new_PSIdf['Updated_ItemID'] = Updted_ItemID
        new_PSIDFlist.append(new_PSIdf)
    return new_PSIDFlist

"""### 5.Prediction"""

# def topN_Index(arr_row, n):
#     sort_index = np.argsort(-arr_row)          ##get ascending order of sort
#     sort_index = sort_index[:n]
#     return sort_index

def topN_Index(a, n):
    parted = np.argpartition(a, -n)[-n:]
    return parted[np.argsort(-a[parted])]    

def TopNPred(RatingMat,holdout,V, user_column, N):  ##N == Top_N
    TestUsers = holdout[user_column]
    HOLDOUT_usersMat = RatingMat[TestUsers,:]         ##this doubles as the "previously seen items"
    PVVT =  HOLDOUT_usersMat.dot(V).dot(V.T) 
    users_column = HOLDOUT_usersMat.nonzero()[0]
    items_column = HOLDOUT_usersMat.nonzero()[1]
    args = np.array([users_column,items_column])
    np.put(PVVT, np.ravel_multi_index(args, PVVT.shape),-np.inf)   ##downsample previously seen items
    TopN_pred = np.apply_along_axis(topN_Index, 1,PVVT,n = N)
    return TopN_pred

def getALLTopNPred(RatingMat_List,HOLDOUT_list,V_list,user_column,N):
    All_TOPN_PRED = []
    for RatingMat,holdout,V in zip(RatingMat_List,HOLDOUT_list,V_list):  
        TopN_pred =  TopNPred(RatingMat,holdout,V, user_column, N)
        All_TOPN_PRED.append(TopN_pred)
    return All_TOPN_PRED

def TQDMgetALLTopNPred(RatingMat_List,HOLDOUT_list,V_list,user_column,N):
  All_TOPN_PRED = []
  for RatingMat,holdout,V in tqdm(zip(RatingMat_List,HOLDOUT_list,V_list)):  
    TopN_pred =  TopNPred(RatingMat,holdout,V, user_column, N)
    All_TOPN_PRED.append(TopN_pred)
  return All_TOPN_PRED

def TopNPred_ALLUSERS(RatingMat,V, N):  ##Prediction for all users ...||Not just Holdout
  PVVT =  RatingMat.dot(V).dot(V.T) 
  users_column = RatingMat.nonzero()[0]
  items_column = RatingMat.nonzero()[1]
  args = np.array([users_column,items_column])
  np.put(PVVT, np.ravel_multi_index(args, PVVT.shape),-np.inf)   ##downsample previously seen items
  TopN_pred = np.apply_along_axis(topN_Index, 1,PVVT,n = N)
  return TopN_pred

def getALLTopNPred_ALLUSERS(RatingMat_List,V_list,N):
  All_TOPN_PRED = []
  for RatingMat,V in zip(RatingMat_List,V_list):   
    TopN_pred =  TopNPred_ALLUSERS(RatingMat,V, N)
    All_TOPN_PRED.append(TopN_pred)
  return All_TOPN_PRED

def TQDMgetALLTopNPred_ALLUSERS(RatingMat_List,V_list,N):
  All_TOPN_PRED = []
  for RatingMat,V in tqdm(zip(RatingMat_List,V_list)):  
    TopN_pred =  TopNPred_ALLUSERS(RatingMat,V, N)
    All_TOPN_PRED.append(TopN_pred)
  return All_TOPN_PRED

"""### 6.Evaluation"""

def Hitrate_Eval(Holdout,TopN_pred,user_column,item_column):
    Eval_itemsVector  =  Holdout[[item_column]].to_numpy()
    HitRate_arr   =  (TopN_pred == Eval_itemsVector).sum(axis=1)  ##sum along row...
    HitCount = np.count_nonzero(HitRate_arr == 1)
    HitRate_ = HitRate_arr.mean()
    print("Number of hits: ", HitCount)
    print("Total Num of users: ",len(Holdout[user_column]))
    print("Recommendation HitRate: ",HitRate_)
    return HitRate_


def mean_confidence_interval(data, confidence=0.95):
    a = 1.0 * np.array(data)
    n = len(a)
    mean, se = np.mean(a), st.sem(a)
    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)
    lower_band =  mean-h
    upper_band =  mean+h
    return lower_band, mean,upper_band                ##LowerBand || Mean || UpperBand


def getAll_HitRate(HOLDOUT_list,All_TOPN_PRED,user_column,item_column):
    AllSteps_Hitrate = []
    for Holdout, TopN_pred in zip(HOLDOUT_list,All_TOPN_PRED):
        HitRate_ = Hitrate_Eval(Holdout,TopN_pred,user_column,item_column)
        AllSteps_Hitrate.append(HitRate_)

    LowerBand, Avg_HitRate, UpperBand  = mean_confidence_interval(AllSteps_Hitrate, confidence=0.95)
    print("Average HitRate for All Recommendations: ", Avg_HitRate)
    return AllSteps_Hitrate, LowerBand, Avg_HitRate, UpperBand



"""### 7.Random Rec"""

def TopN_RandomPred(RatingMat,holdout,user_column,N):   ##N == Top_N
  TestUsers = holdout[user_column]
  HOLDOUT_usersMat = RatingMat[TestUsers,:]    
  N_users,N_items = HOLDOUT_usersMat.shape   
  PVVT_RandScores = np.random.rand(N_users,N_items)   ##Assigns random scores to items
  users_column = HOLDOUT_usersMat.nonzero()[0]
  items_column = HOLDOUT_usersMat.nonzero()[1]
  args = np.array([users_column,items_column])
  np.put(PVVT_RandScores, np.ravel_multi_index(args, PVVT_RandScores.shape),-np.inf)   ##downsample previously seen items
  TopN_pred = np.apply_along_axis(topN_Index, 1,PVVT_RandScores,n = N)
  return TopN_pred

def get_ALLRandPred(RatingMat_List,HOLDOUT_list,user_column,N):
  All_RandPred = []
  for RatingMat,holdout in tqdm(zip(RatingMat_List,HOLDOUT_list)):  
    Rand_pred =  TopN_RandomPred(RatingMat,holdout,user_column, N)
    All_RandPred.append(Rand_pred)
  return All_RandPred


def getAll_RandomHitRate(HOLDOUT_list,All_RandPred,user_column,item_column):
  AllSteps_Hitrate = []
  for Holdout, Random_pred in zip(HOLDOUT_list,All_RandPred):  
    HitRate_ = Hitrate_Eval(Holdout,Random_pred,user_column,item_column)
    AllSteps_Hitrate.append(HitRate_)

  LowerBand, Avg_HitRate, UpperBand  = mean_confidence_interval(AllSteps_Hitrate, confidence=0.95)
  print("Average HitRate for All Recommendations: ", Avg_HitRate)
  return AllSteps_Hitrate, LowerBand, Avg_HitRate, UpperBand

def TopN_RandomPred_2(RatingMat,user_column,N):  
  N_users,N_items = RatingMat.shape   
  PVVT_RandScores = np.random.rand(N_users,N_items)   ##Assigns random scores to items
  users_column = RatingMat.nonzero()[0]
  items_column = RatingMat.nonzero()[1]
  args = np.array([users_column,items_column])
  np.put(PVVT_RandScores, np.ravel_multi_index(args, PVVT_RandScores.shape),-np.inf)   ##downsample previously seen items
  TopN_pred = np.apply_along_axis(topN_Index, 1,PVVT_RandScores,n = N)
  return TopN_pred

def get_ALLRandPred_2(RatingMat_List,user_column,N):
  All_RandPred = []
  for RatingMat in tqdm(RatingMat_List):  
    Rand_pred =  TopN_RandomPred_2(RatingMat,user_column, N)
    All_RandPred.append(Rand_pred)
  return All_RandPred


def getAll_RandomHitRate_2(HOLDOUT_list,All_RandPred,user_column,item_column):
  AllSteps_Hitrate = []
  for Holdout, Random_pred in zip(HOLDOUT_list,All_RandPred):  
    TestUsers = Holdout[user_column]
    HOLDOUT_RandPred = Random_pred[TestUsers,:]    
    HitRate_ = Hitrate_Eval(Holdout,HOLDOUT_RandPred,user_column,item_column)
    #HitRate_ = Sample_Hitrate(Holdout,HOLDOUT_RandPred,user_column,item_column)
    AllSteps_Hitrate.append(HitRate_)

  LowerBand, Avg_HitRate, UpperBand  = mean_confidence_interval(AllSteps_Hitrate, confidence=0.95)
  print("Average HitRate for All Recommendations: ", Avg_HitRate)
  return AllSteps_Hitrate, LowerBand, Avg_HitRate, UpperBand

"""### 8.Most POP Rec"""

def getMOSTPOP_Pred(DF,holdout,user_column,item_colum,N):  ##get the most popular item at a particular step
  top_counts= DF.groupby(item_colum)[user_column].count()    
  top_items = top_counts.sort_values(ascending=False) 
  MostPOP_Items = top_items[:N].index.values
  Nusers = holdout[user_column].nunique()  
  MostPOP_Pred = np.array([MostPOP_Items,]*Nusers)
  return MostPOP_Pred

def getAll_MOSTPOP_Pred(DF_list,HOLDOUT_list,user_column,item_colum,N):
  All_MostPOPRED_List = []
  for DF,holdout in zip(DF_list,HOLDOUT_list):
    MostPOP_Pred = getMOSTPOP_Pred(DF,holdout,user_column,item_colum,N)
    All_MostPOPRED_List.append(MostPOP_Pred) 
  return All_MostPOPRED_List

def getAll_MostPOPHitRate(HOLDOUT_list,All_MostPOPRED_List,user_column,item_column):
  AllSteps_Hitrate = []
  for Holdout, MostPOP_pred in zip(HOLDOUT_list,All_MostPOPRED_List): 
    HitRate_ = Hitrate_Eval(Holdout,MostPOP_pred,user_column,item_column)
    AllSteps_Hitrate.append(HitRate_)
  LowerBand, Avg_HitRate, UpperBand  = mean_confidence_interval(AllSteps_Hitrate, confidence=0.95)
  print("Average HitRate for All Recommendations: ", Avg_HitRate)
  return AllSteps_Hitrate, LowerBand, Avg_HitRate, UpperBand    

def getAll_MostPOPHitRate2(HOLDOUT_list,All_MostPOPRED_List,user_column,item_column):
  AllSteps_Hitrate = []
  for Holdout, MostPOP_pred in zip(HOLDOUT_list,All_MostPOPRED_List): 
    TestUsers = Holdout[user_column]
    Holdout_MostPOPred =  MostPOP_pred[TestUsers,:]  ##previous step prediction 
    HitRate_ = Sample_Hitrate(Holdout,Holdout_MostPOPred,user_column,item_column)
    AllSteps_Hitrate.append(HitRate_)
  LowerBand, Avg_HitRate, UpperBand  = mean_confidence_interval(AllSteps_Hitrate, confidence=0.95)
  return AllSteps_Hitrate, LowerBand, Avg_HitRate, UpperBand



"""### 6.Corr Scores """

##weight Jaccard for correlation 
def no_copy_csr_matrix(data, indices, indptr, shape, dtype):
        # set data and indices manually to avoid index dtype checks
        # and thus prevent possible unnecesssary copies of indices
    matrix = csr_matrix(shape, dtype=dtype)
    matrix.data = data
    matrix.indices = indices
    matrix.indptr = indptr
    return matrix

def build_rank_weights_matrix(recommendations, shape):
    recommendations = np.atleast_2d(recommendations)
    n_users, topn = recommendations.shape
    weights_arr = 1. / np.arange(1, topn+1) # 1 / rank
    weights_mat = np.lib.stride_tricks.as_strided(weights_arr, (n_users, topn), (0, weights_arr.itemsize))

    data = weights_mat.ravel()
    indices = recommendations.ravel()
    indptr = np.arange(0, n_users*topn + 1, topn)

    weight_matrix = no_copy_csr_matrix(data, indices, indptr, shape, weights_arr.dtype)
    return weight_matrix

def rank_weighted_jaccard_index(inds1, inds2):
    shape = inds1.shape[0], max(inds1.max(), inds2.max())+1
    weights1 = build_rank_weights_matrix(inds1, shape)
    weights2 = build_rank_weights_matrix(inds2, shape)
    jaccard_index = weights1.minimum(weights2).sum(axis=1) / weights1.maximum(weights2).sum(axis=1)
    return np.asarray(jaccard_index).squeeze()



def getAll_AvgCorr(All_PRED,Corr_steps_):
    All_Corr_List = []
    for step in Corr_steps_:
        corr_result = rank_weighted_jaccard_index(All_PRED[step-1], All_PRED[step])  ##corr values for all users at each dual step
        All_Corr_List.append(corr_result) 
    AUserC_arry = np.array(All_Corr_List).T      
    return AUserC_arry      ##corr values for all users at every step for a single rank  ##rows == users || column : steps





#####All Ranks CorrrScores 
def PSICorr_4AllRanks(SVDTrCorr_MatList,A0_Corr_Mat,PSI_TrCorr_Mat,PSI_TestCorr_Mat,Corr_steps_,start_value,MAX_RANK,increment,N,SAVE_name):
    print("Correlation for Allusers: ")
    All_UsersCorrPSI = []
    for rank in tqdm(range(start_value,MAX_RANK+1,increment)): 
        Vpsi_list =  integratorOnMat(A0_Corr_Mat,PSI_TrCorr_Mat,PSI_TestCorr_Mat,k=rank) 
        ALLPredPSI = getALLTopNPred_ALLUSERS(SVDTrCorr_MatList,Vpsi_list,N)   ##SVDtrain_MatList == UserHistMat
        AUsersCorr_ = getAll_AvgCorr(ALLPredPSI,Corr_steps_)    #Avg_AAUsersPSI
        All_UsersCorrPSI.append(AUsersCorr_)
    #np.save(df_+SAVE_name,All_UsersCorrPSI) 
    return All_UsersCorrPSI

def Updt_getAll_AvgCorr(All_PRED,SVDTrain_list,Corr_steps_,user_name):
    All_Corr_List = []
    for step in Corr_steps_:
        prev_users = SVDTrain_list[step-1][user_name].unique()
        PREV_StepPred = All_PRED[step-1]
        CURR_StepPred = All_PRED[step][prev_users,:]
        corr_result = rank_weighted_jaccard_index(PREV_StepPred, CURR_StepPred)  ##corr values for all users at each dual step
        All_Corr_List.append(corr_result) 
    AUserC_arry = np.array(All_Corr_List).T      
    return AUserC_arry      #corr values for all users at every step



